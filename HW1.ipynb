{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Option 1: Specify the absolute path to the file\n",
    "load_dotenv('C:\\\\Users\\\\TERENTI\\\\Desktop\\\\UNI\\\\LLM\\\\api_key.env')\n",
    "\n",
    "# Now you can access the API key\n",
    "api_key = os.getenv('API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Gemini Model: gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "#initializing model \n",
    "model_name = 'gemini-2.0-flash'\n",
    "\n",
    "\n",
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=model_name,\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.0,\n",
    "    # Gemini can sometimes benefit from converting system messages\n",
    "    # if you encounter issues with prompts that rely heavily on system roles.\n",
    "    convert_system_message_to_human=True\n",
    ")\n",
    "\n",
    "print(f\"Initialized Gemini Model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATA INTRODUCTION\n",
      "==================================================\n",
      "\n",
      "üìä SHAPE:\n",
      "    Rows: 66\n",
      "    Columns: 21\n",
      "\n",
      "üìã COLUMNS:\n",
      "    1. Year\n",
      "    2. crimes.total\n",
      "    3. crimes.penal.code\n",
      "    4. crimes.person\n",
      "    5. murder\n",
      "    6. assault\n",
      "    7. sexual.offenses\n",
      "    8. rape\n",
      "    9. stealing.general\n",
      "    10. burglary\n",
      "    11. house.theft\n",
      "    12. vehicle.theft\n",
      "    13. out.of.vehicle.theft\n",
      "    14. shop.theft\n",
      "    15. robbery\n",
      "    16. fraud\n",
      "    17. criminal.damage\n",
      "    18. other.penal.crimes\n",
      "    19. narcotics\n",
      "    20. drunk.driving\n",
      "    21. population\n",
      "\n",
      "üìù DATA TYPES:\n",
      "    Year: int64\n",
      "    crimes.total: int64\n",
      "    crimes.penal.code: int64\n",
      "    crimes.person: int64\n",
      "    murder: int64\n",
      "    assault: int64\n",
      "    sexual.offenses: int64\n",
      "    rape: int64\n",
      "    stealing.general: int64\n",
      "    burglary: int64\n",
      "    house.theft: float64\n",
      "    vehicle.theft: float64\n",
      "    out.of.vehicle.theft: float64\n",
      "    shop.theft: float64\n",
      "    robbery: int64\n",
      "    fraud: int64\n",
      "    criminal.damage: int64\n",
      "    other.penal.crimes: int64\n",
      "    narcotics: float64\n",
      "    drunk.driving: int64\n",
      "    population: int64\n",
      "\n",
      "‚ùì MISSING VALUES:\n",
      "    Year: 0 values (0.00%)\n",
      "    crimes.total: 0 values (0.00%)\n",
      "    crimes.penal.code: 0 values (0.00%)\n",
      "    crimes.person: 0 values (0.00%)\n",
      "    murder: 0 values (0.00%)\n",
      "    assault: 0 values (0.00%)\n",
      "    sexual.offenses: 0 values (0.00%)\n",
      "    rape: 0 values (0.00%)\n",
      "    stealing.general: 0 values (0.00%)\n",
      "    burglary: 0 values (0.00%)\n",
      "    house.theft: 15 values (22.73%)\n",
      "    vehicle.theft: 7 values (10.61%)\n",
      "    out.of.vehicle.theft: 15 values (22.73%)\n",
      "    shop.theft: 15 values (22.73%)\n",
      "    robbery: 0 values (0.00%)\n",
      "    fraud: 0 values (0.00%)\n",
      "    criminal.damage: 0 values (0.00%)\n",
      "    other.penal.crimes: 0 values (0.00%)\n",
      "    narcotics: 4 values (6.06%)\n",
      "    drunk.driving: 0 values (0.00%)\n",
      "    population: 0 values (0.00%)\n",
      "\n",
      "üìÑ SAMPLE ROWS:\n",
      "    Row 1:\n",
      "        Year: 1950\n",
      "        crimes.total: 2784\n",
      "        crimes.penal.code: 2306\n",
      "        crimes.person: 120\n",
      "        murder: 1\n",
      "        assault: 105\n",
      "        sexual.offenses: 40\n",
      "        rape: 5\n",
      "        stealing.general: 1578\n",
      "        burglary: 295\n",
      "        house.theft: nan\n",
      "        vehicle.theft: nan\n",
      "        out.of.vehicle.theft: nan\n",
      "        shop.theft: nan\n",
      "        robbery: 3\n",
      "        fraud: 209\n",
      "        criminal.damage: 72\n",
      "        other.penal.crimes: 477\n",
      "        narcotics: 0.0\n",
      "        drunk.driving: 49\n",
      "        population: 7014000\n",
      "\n",
      "    Row 2:\n",
      "        Year: 1951\n",
      "        crimes.total: 3284\n",
      "        crimes.penal.code: 2754\n",
      "        crimes.person: 125\n",
      "        murder: 1\n",
      "        assault: 109\n",
      "        sexual.offenses: 45\n",
      "        rape: 6\n",
      "        stealing.general: 1899\n",
      "        burglary: 342\n",
      "        house.theft: nan\n",
      "        vehicle.theft: nan\n",
      "        out.of.vehicle.theft: nan\n",
      "        shop.theft: nan\n",
      "        robbery: 3\n",
      "        fraud: 310\n",
      "        criminal.damage: 73\n",
      "        other.penal.crimes: 530\n",
      "        narcotics: 0.0\n",
      "        drunk.driving: 66\n",
      "        population: 7073000\n",
      "\n",
      "    Row 3:\n",
      "        Year: 1952\n",
      "        crimes.total: 3160\n",
      "        crimes.penal.code: 2608\n",
      "        crimes.person: 119\n",
      "        murder: 1\n",
      "        assault: 104\n",
      "        sexual.offenses: 39\n",
      "        rape: 4\n",
      "        stealing.general: 1846\n",
      "        burglary: 372\n",
      "        house.theft: nan\n",
      "        vehicle.theft: nan\n",
      "        out.of.vehicle.theft: nan\n",
      "        shop.theft: nan\n",
      "        robbery: 3\n",
      "        fraud: 217\n",
      "        criminal.damage: 82\n",
      "        other.penal.crimes: 553\n",
      "        narcotics: 0.0\n",
      "        drunk.driving: 78\n",
      "        population: 7125000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'shape': (66, 21),\n",
       " 'columns': ['Year',\n",
       "  'crimes.total',\n",
       "  'crimes.penal.code',\n",
       "  'crimes.person',\n",
       "  'murder',\n",
       "  'assault',\n",
       "  'sexual.offenses',\n",
       "  'rape',\n",
       "  'stealing.general',\n",
       "  'burglary',\n",
       "  'house.theft',\n",
       "  'vehicle.theft',\n",
       "  'out.of.vehicle.theft',\n",
       "  'shop.theft',\n",
       "  'robbery',\n",
       "  'fraud',\n",
       "  'criminal.damage',\n",
       "  'other.penal.crimes',\n",
       "  'narcotics',\n",
       "  'drunk.driving',\n",
       "  'population'],\n",
       " 'dtypes': {'Year': dtype('int64'),\n",
       "  'crimes.total': dtype('int64'),\n",
       "  'crimes.penal.code': dtype('int64'),\n",
       "  'crimes.person': dtype('int64'),\n",
       "  'murder': dtype('int64'),\n",
       "  'assault': dtype('int64'),\n",
       "  'sexual.offenses': dtype('int64'),\n",
       "  'rape': dtype('int64'),\n",
       "  'stealing.general': dtype('int64'),\n",
       "  'burglary': dtype('int64'),\n",
       "  'house.theft': dtype('float64'),\n",
       "  'vehicle.theft': dtype('float64'),\n",
       "  'out.of.vehicle.theft': dtype('float64'),\n",
       "  'shop.theft': dtype('float64'),\n",
       "  'robbery': dtype('int64'),\n",
       "  'fraud': dtype('int64'),\n",
       "  'criminal.damage': dtype('int64'),\n",
       "  'other.penal.crimes': dtype('int64'),\n",
       "  'narcotics': dtype('float64'),\n",
       "  'drunk.driving': dtype('int64'),\n",
       "  'population': dtype('int64')},\n",
       " 'missing_values': {'Year': {'count': 0, 'percentage': 0.0},\n",
       "  'crimes.total': {'count': 0, 'percentage': 0.0},\n",
       "  'crimes.penal.code': {'count': 0, 'percentage': 0.0},\n",
       "  'crimes.person': {'count': 0, 'percentage': 0.0},\n",
       "  'murder': {'count': 0, 'percentage': 0.0},\n",
       "  'assault': {'count': 0, 'percentage': 0.0},\n",
       "  'sexual.offenses': {'count': 0, 'percentage': 0.0},\n",
       "  'rape': {'count': 0, 'percentage': 0.0},\n",
       "  'stealing.general': {'count': 0, 'percentage': 0.0},\n",
       "  'burglary': {'count': 0, 'percentage': 0.0},\n",
       "  'house.theft': {'count': 15, 'percentage': 22.727272727272727},\n",
       "  'vehicle.theft': {'count': 7, 'percentage': 10.606060606060606},\n",
       "  'out.of.vehicle.theft': {'count': 15, 'percentage': 22.727272727272727},\n",
       "  'shop.theft': {'count': 15, 'percentage': 22.727272727272727},\n",
       "  'robbery': {'count': 0, 'percentage': 0.0},\n",
       "  'fraud': {'count': 0, 'percentage': 0.0},\n",
       "  'criminal.damage': {'count': 0, 'percentage': 0.0},\n",
       "  'other.penal.crimes': {'count': 0, 'percentage': 0.0},\n",
       "  'narcotics': {'count': 4, 'percentage': 6.0606060606060606},\n",
       "  'drunk.driving': {'count': 0, 'percentage': 0.0},\n",
       "  'population': {'count': 0, 'percentage': 0.0}},\n",
       " 'sample_rows': [{'Year': 1950,\n",
       "   'crimes.total': 2784,\n",
       "   'crimes.penal.code': 2306,\n",
       "   'crimes.person': 120,\n",
       "   'murder': 1,\n",
       "   'assault': 105,\n",
       "   'sexual.offenses': 40,\n",
       "   'rape': 5,\n",
       "   'stealing.general': 1578,\n",
       "   'burglary': 295,\n",
       "   'house.theft': nan,\n",
       "   'vehicle.theft': nan,\n",
       "   'out.of.vehicle.theft': nan,\n",
       "   'shop.theft': nan,\n",
       "   'robbery': 3,\n",
       "   'fraud': 209,\n",
       "   'criminal.damage': 72,\n",
       "   'other.penal.crimes': 477,\n",
       "   'narcotics': 0.0,\n",
       "   'drunk.driving': 49,\n",
       "   'population': 7014000},\n",
       "  {'Year': 1951,\n",
       "   'crimes.total': 3284,\n",
       "   'crimes.penal.code': 2754,\n",
       "   'crimes.person': 125,\n",
       "   'murder': 1,\n",
       "   'assault': 109,\n",
       "   'sexual.offenses': 45,\n",
       "   'rape': 6,\n",
       "   'stealing.general': 1899,\n",
       "   'burglary': 342,\n",
       "   'house.theft': nan,\n",
       "   'vehicle.theft': nan,\n",
       "   'out.of.vehicle.theft': nan,\n",
       "   'shop.theft': nan,\n",
       "   'robbery': 3,\n",
       "   'fraud': 310,\n",
       "   'criminal.damage': 73,\n",
       "   'other.penal.crimes': 530,\n",
       "   'narcotics': 0.0,\n",
       "   'drunk.driving': 66,\n",
       "   'population': 7073000},\n",
       "  {'Year': 1952,\n",
       "   'crimes.total': 3160,\n",
       "   'crimes.penal.code': 2608,\n",
       "   'crimes.person': 119,\n",
       "   'murder': 1,\n",
       "   'assault': 104,\n",
       "   'sexual.offenses': 39,\n",
       "   'rape': 4,\n",
       "   'stealing.general': 1846,\n",
       "   'burglary': 372,\n",
       "   'house.theft': nan,\n",
       "   'vehicle.theft': nan,\n",
       "   'out.of.vehicle.theft': nan,\n",
       "   'shop.theft': nan,\n",
       "   'robbery': 3,\n",
       "   'fraud': 217,\n",
       "   'criminal.damage': 82,\n",
       "   'other.penal.crimes': 553,\n",
       "   'narcotics': 0.0,\n",
       "   'drunk.driving': 78,\n",
       "   'population': 7125000}],\n",
       " 'numeric_stats': {}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_intro(df):\n",
    "    # Create profile dictionary\n",
    "    profile = {\n",
    "        \"shape\": df.shape,\n",
    "        \"columns\": list(df.columns),\n",
    "        \"dtypes\": df.dtypes.to_dict(),\n",
    "        \"missing_values\": {col: {\"count\": int(df[col].isnull().sum()), \n",
    "                                \"percentage\": float(df[col].isnull().mean() * 100)} \n",
    "                        for col in df.columns},\n",
    "        \"sample_rows\": df.head(3).to_dict(orient='records'),\n",
    "        \"numeric_stats\": {}\n",
    "    }\n",
    "    \n",
    "    # Print each section with formatting\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA INTRODUCTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nüìä SHAPE:\")\n",
    "    print(f\"    Rows: {profile['shape'][0]}\")\n",
    "    print(f\"    Columns: {profile['shape'][1]}\")\n",
    "    \n",
    "    print(\"\\nüìã COLUMNS:\")\n",
    "    for i, col in enumerate(profile['columns'], 1):\n",
    "        print(f\"    {i}. {col}\")\n",
    "    \n",
    "    print(\"\\nüìù DATA TYPES:\")\n",
    "    for col, dtype in profile['dtypes'].items():\n",
    "        print(f\"    {col}: {dtype}\")\n",
    "    \n",
    "    print(\"\\n‚ùì MISSING VALUES:\")\n",
    "    for col, missing in profile['missing_values'].items():\n",
    "        print(f\"    {col}: {missing['count']} values ({missing['percentage']:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nüìÑ SAMPLE ROWS:\")\n",
    "    for i, row in enumerate(profile['sample_rows'], 1):\n",
    "        print(f\"    Row {i}:\")\n",
    "        for col, val in row.items():\n",
    "            print(f\"        {col}: {val}\")\n",
    "        print()\n",
    "    \n",
    "    return profile\n",
    "\n",
    "df = pd.read_csv('reported.csv')\n",
    "data_intro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Document (First Row) ---\n",
      "page_content='Year: 1950\n",
      "crimes.total: 2784\n",
      "crimes.penal.code: 2306\n",
      "crimes.person: 120\n",
      "murder: 1\n",
      "assault: 105\n",
      "sexual.offenses: 40\n",
      "rape: 5\n",
      "stealing.general: 1578\n",
      "burglary: 295\n",
      "house.theft: NA\n",
      "vehicle.theft: NA\n",
      "out.of.vehicle.theft: NA\n",
      "shop.theft: NA\n",
      "robbery: 3\n",
      "fraud: 209\n",
      "criminal.damage: 72\n",
      "other.penal.crimes: 477\n",
      "narcotics: 0\n",
      "drunk.driving: 49\n",
      "population: 7014000' metadata={'source': 'C:\\\\Users\\\\TERENTI\\\\Desktop\\\\UNI\\\\LLM\\\\HW\\\\reported.csv', 'row': 0}\n",
      "\n",
      "--- Page Content Only ---\n",
      "Year: 1950\n",
      "crimes.total: 2784\n",
      "crimes.penal.code: 2306\n",
      "crimes.person: 120\n",
      "murder: 1\n",
      "assault: 105\n",
      "sexual.offenses: 40\n",
      "rape: 5\n",
      "stealing.general: 1578\n",
      "burglary: 295\n",
      "house.theft: NA\n",
      "vehicle.theft: NA\n",
      "out.of.vehicle.theft: NA\n",
      "shop.theft: NA\n",
      "robbery: 3\n",
      "fraud: 209\n",
      "criminal.damage: 72\n",
      "other.penal.crimes: 477\n",
      "narcotics: 0\n",
      "drunk.driving: 49\n",
      "population: 7014000\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(r'C:\\Users\\TERENTI\\Desktop\\UNI\\LLM\\HW\\reported.csv')\n",
    "data=loader.load()\n",
    "\n",
    "\n",
    "\n",
    "# --- Inspect the First Document ---\n",
    "first_doc = data[0]\n",
    "row_content = first_doc.page_content\n",
    "row_metadata = first_doc.metadata\n",
    "\n",
    "print(\"--- Original Document (First Row) ---\")\n",
    "print(first_doc)\n",
    "print(\"\\n--- Page Content Only ---\")\n",
    "print(row_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TERENTI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "c:\\Users\\TERENTI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
      "c:\\Users\\TERENTI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I understand.  Given that I *still* cannot access the data, I will create a **simulated prediction for 2016** based on the simulated trends from my previous response.  This is purely hypothetical and based on the assumptions I made earlier.  It's crucial to remember that this is *not* a real prediction and should not be taken as such.  It's an illustration of how I would use the trends to extrapolate.\n",
      "\n",
      "**Simulated Prediction for 2016 Crime Statistics**\n",
      "\n",
      "**Assumptions (Based on Previous Simulated Analysis):**\n",
      "\n",
      "*   **Overall Crime Rate:**  The overall crime rate (excluding `crimes.total`) has been declining or stabilizing in recent years (let's say from 2000 onwards).\n",
      "*   **Population Growth:**  Population continues to grow at a moderate rate.\n",
      "*   **Specific Crime Trends:**\n",
      "    *   **Murder:**  Continuing a slow decline.\n",
      "    *   **Assault:**  Stabilizing or slightly increasing.\n",
      "    *   **Sexual Offenses & Rape:**  Continuing to increase, but at a slower rate than previously.\n",
      "    *   **Burglary:**  Continuing to decline.\n",
      "    *   **Vehicle Theft:**  Continuing to decline.\n",
      "    *   **Robbery:**  Relatively stable.\n",
      "    *   **Fraud:**  Continuing to increase significantly due to online activity.\n",
      "    *   **Narcotics:**  Stabilizing or slightly declining due to changing drug policies or enforcement.\n",
      "    *   **Drunk Driving:**  Continuing to decline due to stricter laws and enforcement.\n",
      "\n",
      "**Extrapolation Method:**\n",
      "\n",
      "I will use a simple linear extrapolation based on the trends observed in the simulated data from, say, 2010-2015.  This is a very basic method and more sophisticated techniques (e.g., time series analysis, regression models) would be used with real data.\n",
      "\n",
      "**Simulated 2016 Prediction (Rates per 100,000 Population):**\n",
      "\n",
      "Let's assume the following simulated rates per 100,000 population for 2015 (these are *completely made up* for this example):\n",
      "\n",
      "*   Murder: 5.0\n",
      "*   Assault: 350.0\n",
      "*   Sexual Offenses: 50.0\n",
      "*   Rape: 30.0\n",
      "*   Burglary: 400.0\n",
      "*   Vehicle Theft: 250.0\n",
      "*   Robbery: 100.0\n",
      "*   Fraud: 600.0\n",
      "*   Narcotics: 200.0\n",
      "*   Drunk Driving: 80.0\n",
      "\n",
      "Now, let's assume the following *annual changes* based on the simulated trends from 2010-2015 (again, *completely made up*):\n",
      "\n",
      "*   Murder: -0.2\n",
      "*   Assault: +2.0\n",
      "*   Sexual Offenses: +1.0\n",
      "*   Rape: +0.5\n",
      "*   Burglary: -10.0\n",
      "*   Vehicle Theft: -5.0\n",
      "*   Robbery: +0.0\n",
      "*   Fraud: +30.0\n",
      "*   Narcotics: -2.0\n",
      "*   Drunk Driving: -3.0\n",
      "\n",
      "**Predicted 2016 Rates (per 100,000):**\n",
      "\n",
      "*   Murder: 5.0 - 0.2 = **4.8**\n",
      "*   Assault: 350.0 + 2.0 = **352.0**\n",
      "*   Sexual Offenses: 50.0 + 1.0 = **51.0**\n",
      "*   Rape: 30.0 + 0.5 = **30.5**\n",
      "*   Burglary: 400.0 - 10.0 = **390.0**\n",
      "*   Vehicle Theft: 250.0 - 5.0 = **245.0**\n",
      "*   Robbery: 100.0 + 0.0 = **100.0**\n",
      "*   Fraud: 600.0 + 30.0 = **630.0**\n",
      "*   Narcotics: 200.0 - 2.0 = **198.0**\n",
      "*   Drunk Driving: 80.0 - 3.0 = **77.0**\n",
      "\n",
      "**Important Disclaimer:**\n",
      "\n",
      "**These are *completely simulated* predictions based on *completely simulated* trends.  They are for illustrative purposes only and should not be interpreted as actual forecasts.  The accuracy of any prediction depends entirely on the quality and representativeness of the underlying data and the appropriateness of the chosen forecasting method.**\n",
      "\n",
      "**In summary, I have provided a simulated prediction for 2016 based on the hypothetical trends I described earlier.  This demonstrates the process I would follow if I had access to the actual data.  Remember that this is not a real prediction.**\n"
     ]
    }
   ],
   "source": [
    "#SHOWCASE THAT DOESNT WORKS\n",
    "\n",
    "\n",
    "\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "topic_prompt = PromptTemplate(\n",
    "    input_variable=['inference'],\n",
    "    template ='go through the given task step by step, take the most significant information and at every step ask critically evaluate you result, and only after that give the answe on the given {inference}, do not count year and total crime rate as the inference, its more like result of this year like it is in the logistic linear regression'\n",
    ")\n",
    "chain_inference = LLMChain(llm=llm_model, prompt=topic_prompt)\n",
    "# print(result)\n",
    "\n",
    "\n",
    "# topic_prompt2=PromptTemplate(\n",
    "#     input_variables=['correlation'],\n",
    "#     template='based on the columns tell me which one of the columns has the heighest {correlation}, also tell me what is their correlation coefficent,Do not count and year correlation, it doesnt make any sense to do so'\n",
    "# )\n",
    "# chain_correlation = LLMChain(llm=llm_model, prompt=topic_prompt2)\n",
    "\n",
    "\n",
    "topic_prompt3 = PromptTemplate(\n",
    "    input_variables=['loss'],\n",
    "    template='on the prevois correlation columns ignor the {loss}, and provide this data'\n",
    ")\n",
    "chain_clean=LLMChain(llm=llm_model, prompt=topic_prompt3)\n",
    "\n",
    "\n",
    "topic_prompt4=PromptTemplate(\n",
    "    input_variables=['prediction'],\n",
    "    template='NOW, tell what would the crime statistics in 2016 as the {prediction}, for the given data as good as you can, final output must be prediciton its a must'\n",
    ")\n",
    "chain_predict = LLMChain(llm=llm_model, prompt=topic_prompt4)\n",
    "\n",
    "main_chain=SimpleSequentialChain(chains=[chain_inference,chain_clean, chain_predict])\n",
    "output= main_chain.run(data)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Requesting Cleaning Analysis from LLM ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TERENTI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LLM Analysis Result ---\n",
      "{'row_data': 'Year: 1950\\ncrimes.total: 2784\\ncrimes.penal.code: 2306\\ncrimes.person: 120\\nmurder: 1\\nassault: 105\\nsexual.offenses: 40\\nrape: 5\\nstealing.general: 1578\\nburglary: 295\\nhouse.theft: NA\\nvehicle.theft: NA\\nout.of.vehicle.theft: NA\\nshop.theft: NA\\nrobbery: 3\\nfraud: 209\\ncriminal.damage: 72\\nother.penal.crimes: 477\\nnarcotics: 0\\ndrunk.driving: 49\\npopulation: 7014000', 'source': 'C:\\\\Users\\\\TERENTI\\\\Desktop\\\\UNI\\\\LLM\\\\HW\\\\reported.csv', 'row_num': 0, 'text': 'Okay, let\\'s analyze the provided data row for potential data quality issues.\\n\\n**Analysis Report:**\\n\\n1.  **Missing Values:**\\n    - **Problem:** Several fields have \"NA\" which likely represents missing data.\\n    - **Affected Fields:** `house.theft`, `vehicle.theft`, `out.of.vehicle.theft`, `shop.theft`\\n    - **Cleaning Action:**  Replace \"NA\" with a more appropriate representation of missing data.  Options include:\\n        *   Replacing with `NULL` (if the database supports it).\\n        *   Replacing with `0` if it\\'s reasonable to assume a zero value when data is missing (e.g., if these represent counts).  This should be done cautiously and documented.\\n        *   Leaving as `NA` but ensuring the data processing pipeline handles `NA` values correctly.\\n        *   Replacing with the mean/median of the column (imputation), but this should be done with caution and documented.\\n\\n2.  **Data Type Issues:**\\n    - **Problem:** All numerical fields should be integers, but the missing values represented as \"NA\" will cause issues if the column is interpreted as numeric.\\n    - **Affected Fields:** `house.theft`, `vehicle.theft`, `out.of.vehicle.theft`, `shop.theft`\\n    - **Cleaning Action:** Ensure that after handling the missing values (as described above), the columns are correctly interpreted as numeric (integer) types.\\n\\n3.  **Consistency/Validity:**\\n    - **Problem:** It\\'s worth checking if the sum of individual crime categories roughly adds up to the total crimes. This can help identify potential data entry errors or inconsistencies in how crimes are categorized.\\n    - **Affected Fields:** `crimes.total`, `crimes.penal.code`, `crimes.person`, `murder`, `assault`, `sexual.offenses`, `rape`, `stealing.general`, `burglary`, `house.theft`, `vehicle.theft`, `out.of.vehicle.theft`, `shop.theft`, `robbery`, `fraud`, `criminal.damage`, `other.penal.crimes`, `narcotics`, `drunk.driving`\\n    - **Cleaning Action:** Calculate the sum of the individual crime categories (after handling missing values). Compare this sum to `crimes.total`. If there\\'s a significant discrepancy, investigate further to determine the source of the error (e.g., miscategorization, data entry error).  The `crimes.penal.code` and `crimes.person` categories should also be considered when checking the sum.\\n\\n4. **Other Issues:**\\n    - **Problem:** The column names use periods (`.`) as separators. While this might be acceptable, it can sometimes cause issues with certain data processing tools or programming languages.\\n    - **Affected Fields:** All column names.\\n    - **Cleaning Action:** Consider replacing the periods with underscores (`_`) for better compatibility (e.g., `crimes.total` becomes `crimes_total`).\\n\\n**Summary:**\\n\\nThe primary issues are the missing values represented by \"NA\" and the need to ensure data type consistency after handling these missing values.  A consistency check of the crime counts is also recommended.  Finally, consider renaming columns to use underscores instead of periods.'}\n"
     ]
    }
   ],
   "source": [
    "#Second sequantial prompt WORKS better\n",
    "analysis_template = \"\"\"\n",
    "You are a data cleaning assistant. Analyze the following data row extracted from a CSV file.\n",
    "The row content is:\n",
    "---\n",
    "{row_data}\n",
    "---\n",
    "The row comes from source '{source}' and is row number {row_num}.\n",
    "\n",
    "Based on typical data quality standards and the likely structure of this data (inferring columns if possible, e.g., [\"Date\", \"City\", \"Event Type\", \"Value\", \"Notes\"]), please identify potential issues:\n",
    "\n",
    "1.  **Missing Values:** Are there any empty fields, or fields containing placeholders like 'NA', 'None', 'null', '?', '--'?\n",
    "2.  **Formatting Errors:** Check for inconsistent date/time formats (suggest a standard like YYYY-MM-DD), numbers with extra characters, inconsistent capitalization, leading/trailing whitespace.\n",
    "3.  **Data Type Issues:** Does any field seem to have the wrong type (e.g., text in a numeric column)?\n",
    "4.  **Consistency/Validity:** Are there potential typos? Do categorical values seem consistent? Are there values that seem logically impossible (e.g., a future date for a past event)?\n",
    "5.  **Other Issues:** Anything else that looks suspicious?\n",
    "\n",
    "For each issue found:\n",
    "- Describe the problem clearly.\n",
    "- Indicate the specific field or value affected.\n",
    "- Suggest a concrete cleaning action (e.g., \"Remove leading whitespace\", \"Convert to YYYY-MM-DD\", \"Replace 'NA' with 0\", \"Correct typo 'Cty' to 'City'\").\n",
    "\n",
    "If the row appears clean based on these checks, state \"No major issues found.\"\n",
    "\n",
    "Analysis Report:\n",
    "\"\"\"\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(analysis_template)\n",
    "\n",
    "# --- Create and Run the Analysis Chain ---\n",
    "# Use a simple string output parser to get the LLM's text response\n",
    "analysis_chain = LLMChain(llm=llm_model, prompt=analysis_prompt, output_parser=StrOutputParser())\n",
    "\n",
    "print(\"\\n--- Requesting Cleaning Analysis from LLM ---\")\n",
    "try:\n",
    "    # Provide the row content and metadata to the prompt\n",
    "    analysis_result = analysis_chain.invoke({\n",
    "        \"row_data\": row_content,\n",
    "        \"source\": row_metadata.get('source', 'N/A'), # Safely get metadata\n",
    "        \"row_num\": row_metadata.get('row', 'N/A')\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- LLM Analysis Result ---\")\n",
    "    print(analysis_result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError invoking LLM chain: {e}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT\n",
    "import numpy as np\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# 1. First, load the data properly\n",
    "df = pd.read_csv('reported.csv')\n",
    "\n",
    " \n",
    "\n",
    "# 3. Create a data inference function using LLM\n",
    "def analyze_crime_data(query, df):\n",
    "    \"\"\"Use LLM to analyze crime data and answer inference questions\"\"\"\n",
    "    \n",
    "    # Create a summary of the data for context\n",
    "    data_summary = f\"\"\"\n",
    "    This dataset contains crime statistics from {df['Year'].min()} to {df['Year'].max()}.\n",
    "    It includes {df.shape[1]} columns with various crime categories and population data.\n",
    "    Total records: {df.shape[0]}\n",
    "    \n",
    "    Some key columns:\n",
    "    - Year: The year of recorded crimes\n",
    "    - crimes.total: Total number of reported crimes\n",
    "    - crimes.person: Crimes against persons\n",
    "    - murder, assault, rape: Specific violent crime categories\n",
    "    - stealing.general, burglary, robbery: Property crime categories\n",
    "    - population: Population count for the year\n",
    "    \n",
    "    There are some missing values (NA) in certain categories, particularly:\n",
    "    - house.theft: {df['house.theft'].isna().sum()} missing values\n",
    "    - vehicle.theft: {df['vehicle.theft'].isna().sum()} missing values\n",
    "    - shop.theft: {df['shop.theft'].isna().sum()} missing values\n",
    "    - out.of.vehicle.theft: {df['out.of.vehicle.theft'].isna().sum()} missing values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a prompt for the LLM\n",
    "    inference_template = \"\"\"\n",
    "    You are a data analyst specialized in crime statistics. Based on the provided dataset information, \n",
    "    answer the following query with detailed analysis.\n",
    "    \n",
    "    Dataset Summary:\n",
    "    {data_summary}\n",
    "    \n",
    "    User Query: {query}\n",
    "    \n",
    "    Provide a thorough analysis based on the data description. If you cannot answer with certainty,\n",
    "    explain what additional data or analysis would be needed.\n",
    "    \"\"\"\n",
    "    \n",
    "    inference_prompt = ChatPromptTemplate.from_template(inference_template)\n",
    "    \n",
    "    # Create analysis chain\n",
    "    inference_chain = LLMChain(\n",
    "        llm=llm_model,\n",
    "        prompt=inference_prompt,\n",
    "        output_parser=StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = inference_chain.invoke({\n",
    "        \"data_summary\": data_summary,\n",
    "        \"query\": query\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 4. Create a function to replace NA values with column averages\n",
    "def replace_na_with_average(df):\n",
    "    \"\"\"Replace NA values in each column with the column average\"\"\"\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Track what changes were made\n",
    "    changes_report = {}\n",
    "    \n",
    "    # Process each column\n",
    "    for column in cleaned_df.columns:\n",
    "        # Check if column has NA values and is numeric\n",
    "        if cleaned_df[column].isna().any() and np.issubdtype(cleaned_df[column].dtype, np.number):\n",
    "            # Calculate average excluding NA values\n",
    "            avg_value = cleaned_df[column].mean()\n",
    "            # Count NA values\n",
    "            na_count = cleaned_df[column].isna().sum()\n",
    "            # Replace NA with average\n",
    "            cleaned_df[column].fillna(avg_value, inplace=True)\n",
    "            # Record the change\n",
    "            changes_report[column] = {\n",
    "                \"na_count\": int(na_count),\n",
    "                \"replacement_value\": float(avg_value),\n",
    "                \"percentage_affected\": float(na_count / len(cleaned_df) * 100)\n",
    "            }\n",
    "    \n",
    "    return cleaned_df, changes_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TERENTI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCE ANALYSIS:\n",
      "{'data_summary': '\\n    This dataset contains crime statistics from 1950 to 2015.\\n    It includes 21 columns with various crime categories and population data.\\n    Total records: 66\\n\\n    Some key columns:\\n    - Year: The year of recorded crimes\\n    - crimes.total: Total number of reported crimes\\n    - crimes.person: Crimes against persons\\n    - murder, assault, rape: Specific violent crime categories\\n    - stealing.general, burglary, robbery: Property crime categories\\n    - population: Population count for the year\\n\\n    There are some missing values (NA) in certain categories, particularly:\\n    - house.theft: 15 missing values\\n    - vehicle.theft: 7 missing values\\n    - shop.theft: 15 missing values\\n    - out.of.vehicle.theft: 15 missing values\\n    ', 'query': 'What are the trends in violent crimes over time?', 'text': 'Okay, here\\'s an analysis of the trends in violent crimes over time, based on the provided dataset information.\\n\\n**Analysis of Violent Crime Trends (1950-2015)**\\n\\nBased on the dataset description, we can analyze the trends in violent crimes using the following columns:\\n\\n*   `Year`:  Provides the time dimension for our analysis.\\n*   `crimes.person`: Represents the total number of crimes against persons, which is a good proxy for overall violent crime.\\n*   `murder`, `assault`, `rape`:  These columns provide a breakdown of specific types of violent crimes.\\n\\n**Expected Trends and Analysis Steps:**\\n\\n1.  **Overall Violent Crime Trend (using `crimes.person`):**\\n    *   We would expect to see a time series plot of `crimes.person` against `Year`.\\n    *   This plot would reveal whether violent crime has generally increased, decreased, or fluctuated over the 1950-2015 period.\\n    *   We could look for periods of rapid increase or decrease, and identify potential turning points.\\n    *   We could calculate the overall percentage change in `crimes.person` from 1950 to 2015 to quantify the overall trend.\\n\\n2.  **Trends in Specific Violent Crimes (using `murder`, `assault`, `rape`):**\\n    *   We would create time series plots for each of these crime types against `Year`.\\n    *   This would allow us to see if the trends in different types of violent crime are similar or diverge.  For example, murder rates might have decreased while assault rates increased.\\n    *   We could compare the relative magnitudes of these different crime types.  For example, is assault significantly more common than murder?\\n    *   We could calculate the percentage change in each crime type from 1950 to 2015 to compare their individual trends.\\n\\n3.  **Relationship to Population (using `population`):**\\n    *   It\\'s crucial to consider population changes when analyzing crime trends.  An increase in the *number* of crimes might simply be due to a larger population.\\n    *   We would calculate crime rates per capita (e.g., crimes per 100,000 people) for `crimes.person`, `murder`, `assault`, and `rape`.  This would give us a more accurate picture of the *risk* of being a victim of violent crime.\\n    *   We would then plot these crime rates per capita against `Year` to see how the risk of violent crime has changed over time, accounting for population growth.\\n\\n4.  **Correlation Analysis:**\\n    *   Calculate the correlation between `Year` and each of the violent crime variables (`crimes.person`, `murder`, `assault`, `rape`).  This will give a numerical measure of the strength and direction of the relationship.\\n    *   Calculate the correlation between `population` and each of the violent crime variables. This will help determine if population size is a strong predictor of violent crime levels.\\n\\n**Potential Findings and Interpretations:**\\n\\n*   We might find that violent crime increased significantly in the latter half of the 20th century, followed by a decline in recent years.\\n*   We might find that certain types of violent crime (e.g., assault) have increased more than others (e.g., murder).\\n*   We might find that crime rates per capita have remained relatively stable, even though the total number of crimes has increased.\\n*   We might find that population growth is a strong predictor of overall crime levels, but not necessarily of crime rates per capita.\\n\\n**Limitations and Need for Additional Data/Analysis:**\\n\\n*   **Missing Data:** The dataset description mentions missing values in some property crime categories, but not in the violent crime categories. If there are missing values in `crimes.person`, `murder`, `assault`, or `rape`, we would need to address them (e.g., through imputation) before performing the analysis.  Ignoring missing values could bias the results.\\n*   **Geographic Scope:** The dataset description doesn\\'t specify the geographic area covered by the data.  Is it a city, a state, or the entire country?  The trends might be very different depending on the location.  Knowing the geographic scope is essential for interpreting the results.\\n*   **Definition of Crime Categories:**  The dataset description doesn\\'t provide precise definitions of the crime categories.  For example, what specific acts are included in \"assault\"?  Changes in the definition of crime categories over time could affect the observed trends.\\n*   **Socioeconomic Factors:**  The dataset doesn\\'t include any socioeconomic data (e.g., poverty rates, unemployment rates, education levels).  These factors are often strongly correlated with crime rates, and including them in the analysis could provide valuable insights.\\n*   **Law Enforcement Practices:** Changes in law enforcement practices (e.g., increased police presence, changes in arrest policies) could also affect the observed crime trends.  Data on law enforcement practices would be helpful.\\n*   **Reporting Rates:**  Changes in the willingness of victims to report crimes could also affect the observed trends.  If reporting rates have increased over time, this could lead to an apparent increase in crime, even if the actual number of crimes has not changed.\\n\\n**In summary, while we can analyze the trends in violent crimes using the available data, a more complete understanding would require additional data and a more nuanced analysis that considers factors such as geographic scope, socioeconomic conditions, law enforcement practices, and reporting rates.**'}\n",
      "\n",
      "CLEANING REPORT:\n",
      "- house.theft: Replaced 15 NA values with 210.53\n",
      "- vehicle.theft: Replaced 7 NA values with 466.29\n",
      "- out.of.vehicle.theft: Replaced 15 NA values with 1192.57\n",
      "- shop.theft: Replaced 15 NA values with 540.29\n",
      "- narcotics: Replaced 4 NA values with 386.63\n",
      "\n",
      "STATISTICS COMPARISON:\n",
      "- house.theft:\n",
      "  Before: mean=210.53, std=48.68\n",
      "  After:  mean=210.53, std=42.69\n",
      "- vehicle.theft:\n",
      "  Before: mean=466.29, std=193.70\n",
      "  After:  mean=466.29, std=182.97\n",
      "- out.of.vehicle.theft:\n",
      "  Before: mean=1192.57, std=432.54\n",
      "  After:  mean=1192.57, std=379.36\n",
      "- shop.theft:\n",
      "  Before: mean=540.29, std=185.30\n",
      "  After:  mean=540.29, std=162.52\n",
      "- narcotics:\n",
      "  Before: mean=386.63, std=307.13\n",
      "  After:  mean=386.63, std=297.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TERENTI\\AppData\\Local\\Temp\\ipykernel_16096\\2727392121.py:88: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[column].fillna(avg_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. AGENT \n",
    "class CrimeDataAgent:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.cleaned_df = None\n",
    "        self.changes_report = None\n",
    "    \n",
    "    def analyze(self, query):\n",
    "        \"\"\"Answer inference questions about the data\"\"\"\n",
    "        return analyze_crime_data(query, self.df)\n",
    "    \n",
    "    def description(self):\n",
    "        return df.describe()\n",
    "    \n",
    "    def clean_data(self):\n",
    "        \"\"\"Clean data by replacing NA values with column averages\"\"\"\n",
    "        self.cleaned_df, self.changes_report = replace_na_with_average(self.df)\n",
    "        return self.changes_report\n",
    "    \n",
    "    def get_original_data(self):\n",
    "        \"\"\"Return the original dataframe\"\"\"\n",
    "        return self.df\n",
    "    \n",
    "    def get_cleaned_data(self):\n",
    "        \"\"\"Return the cleaned dataframe\"\"\"\n",
    "        if self.cleaned_df is None:\n",
    "            self.clean_data()\n",
    "        return self.cleaned_df\n",
    "    \n",
    "    def compare_stats(self, columns=None):\n",
    "        if self.cleaned_df is None:\n",
    "            self.clean_data()\n",
    "        \n",
    "        if columns is None:\n",
    "            columns = [col for col in self.df.columns if col in self.changes_report]\n",
    "        \n",
    "        comparison = {}\n",
    "        for col in columns:\n",
    "            if col in self.changes_report:\n",
    "                comparison[col] = {\n",
    "                    \"original_mean\": float(self.df[col].mean()),\n",
    "                    \"original_std\": float(self.df[col].std()),\n",
    "                    \"cleaned_mean\": float(self.cleaned_df[col].mean()),\n",
    "                    \"cleaned_std\": float(self.cleaned_df[col].std()),\n",
    "                    \"na_replaced\": self.changes_report[col][\"na_count\"]\n",
    "                }\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "# Example usage:\n",
    "# Initialize the agent\n",
    "crime_agent = CrimeDataAgent(df)\n",
    "\n",
    "# Example 1: Ask an inference question\n",
    "inference_result = crime_agent.analyze(\"What are the trends in violent crimes over time?\")\n",
    "print(\"INFERENCE ANALYSIS:\")\n",
    "print(inference_result)\n",
    "\n",
    "# Example 2: Clean the data by replacing NA values with averages\n",
    "changes = crime_agent.clean_data()\n",
    "print(\"\\nCLEANING REPORT:\")\n",
    "for col, details in changes.items():\n",
    "    print(f\"- {col}: Replaced {details['na_count']} NA values with {details['replacement_value']:.2f}\")\n",
    "    \n",
    "# Example 3: Compare statistics before and after cleaning\n",
    "stats_comparison = crime_agent.compare_stats()\n",
    "print(\"\\nSTATISTICS COMPARISON:\")\n",
    "for col, stats in stats_comparison.items():\n",
    "    print(f\"- {col}:\")\n",
    "    print(f\"  Before: mean={stats['original_mean']:.2f}, std={stats['original_std']:.2f}\")\n",
    "    print(f\"  After:  mean={stats['cleaned_mean']:.2f}, std={stats['cleaned_std']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
